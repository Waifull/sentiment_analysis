{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Wafiul\n",
      "[nltk_data]     Achdi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             content  score sentiment\n",
      "0  Setelah update , kendala \"petama: no yg sudah ...      2   negatif\n",
      "1  Aku kasih bintang 2 ,semenjak wa update terus ...      2   negatif\n",
      "2  Buat aplikasi whatsApp saya minta tolong untuk...      4   positif\n",
      "3  Terima kasih Aplikasi ini sangat membantu untu...      4   positif\n",
      "4  makin di update, makin parah sih kualitas apli...      1   negatif\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('../data/dataset.csv')\n",
    "\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sebelum pemrosesan:\n",
      "                                             content  score sentiment\n",
      "0  Setelah update , kendala \"petama: no yg sudah ...      2   negatif\n",
      "1  Aku kasih bintang 2 ,semenjak wa update terus ...      2   negatif\n",
      "2  Buat aplikasi whatsApp saya minta tolong untuk...      4   positif\n",
      "3  Terima kasih Aplikasi ini sangat membantu untu...      4   positif\n",
      "4  makin di update, makin parah sih kualitas apli...      1   negatif\n",
      "\n",
      "Data setelah pemrosesan:\n",
      "                                             content  \\\n",
      "0  Setelah update , kendala \"petama: no yg sudah ...   \n",
      "1  Aku kasih bintang 2 ,semenjak wa update terus ...   \n",
      "2  Buat aplikasi whatsApp saya minta tolong untuk...   \n",
      "3  Terima kasih Aplikasi ini sangat membantu untu...   \n",
      "4  makin di update, makin parah sih kualitas apli...   \n",
      "\n",
      "                                     cleaned_content  \n",
      "0  updat kendala petama no yg disimpan ilang angk...  \n",
      "1  kasih bintang semenjak wa updat kebanyakan nge...  \n",
      "2  aplikasi whatsapp tolong perbaiki video mengir...  \n",
      "3  terima kasih aplikasi membantu berkomunikasi e...  \n",
      "4  updat parah sih kualita aplikasinya bug pa lay...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "stop_words = set(stopwords.words('indonesian'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def clean_text(text):\n",
    "   \n",
    "    text = text.lower()\n",
    "    \n",
    "   \n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "  \n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    \n",
    "  \n",
    "    text = ' '.join(stemmer.stem(word) for word in text.split())\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "df = pd.read_csv('../data/dataset.csv')\n",
    "\n",
    "\n",
    "print(\"Data sebelum pemrosesan:\")\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "df['cleaned_content'] = df['content'].apply(clean_text)\n",
    "\n",
    "\n",
    "print(\"\\nData setelah pemrosesan:\")\n",
    "print(df[['content', 'cleaned_content']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['cleaned_content'])\n",
    "y = df['sentiment']\n",
    "\n",
    " \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi pada data pelatihan: 100.00%\n",
      "Akurasi pada data pengujian: 100.00%\n"
     ]
    }
   ],
   "source": [
    "model = SVC()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(f'Akurasi pada data pelatihan: {train_accuracy * 100:.2f}%')\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Akurasi pada data pengujian: {test_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(comment):\n",
    "    cleaned_comment = clean_text(comment) \n",
    "    comment_vectorized = vectorizer.transform([cleaned_comment])\n",
    "    return model.predict(comment_vectorized)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentimen: positif\n"
     ]
    }
   ],
   "source": [
    "new_comment = \"Aplikasi ini sangat bagus!\"\n",
    "predicted_sentiment = predict_sentiment(new_comment)\n",
    "print(f'Sentimen: {predicted_sentiment}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentimen: negatif\n"
     ]
    }
   ],
   "source": [
    "new_comment = \"Aplikasi ini sangat jelek!\"\n",
    "predicted_sentiment = predict_sentiment(new_comment)\n",
    "print(f'Sentimen: {predicted_sentiment}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
